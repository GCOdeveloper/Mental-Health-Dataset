{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd08f85a",
   "metadata": {},
   "source": [
    "# Install and import what is necessary to carry out the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717fd64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import os\n",
    "import openai\n",
    "import wandb\n",
    "import pandas as pd\n",
    "import json\n",
    "import random\n",
    "from openai import OpenAI\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import sklearn.metrics\n",
    "from ratelimit import limits, sleep_and_retry\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b93356b",
   "metadata": {},
   "source": [
    "# Code to convert from Excel to JSON format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7195ec8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('CorpusSaludMentalCompleto.xlsx')\n",
    "\n",
    "output_filename = \"base_datos.jsonl\" \n",
    "\n",
    "\n",
    "with open(output_filename, \"w\") as file:\n",
    "    for _, row in df.iterrows():\n",
    "        \n",
    "        data = {\n",
    "                \"messages\": [\n",
    "                    {\n",
    "                        \"role\": \"system\",\n",
    "                        \"content\": \"¿Cual es la emoción del siguiente texto? Responde con 'Amor/Admiración', 'Tristeza/Pena', 'Indeterminado', 'Gratitud', 'Enfado/Desprecio/Burla' o 'Comprensión/Empatía/Identificación'.\"\n",
    "                            # What is the emotion of the following text? \n",
    "                            #Respond with 'Love/Admiration,' 'Sadness,' 'Neutral,' 'Gratitude,' 'Anger/Contempt/Mockery,' or 'Comprehension/Empathy/Identification'\n",
    "                        \n",
    "                            #Label Amor/Admiración is Love/admiration\n",
    "                            #Label Gratitud is Gratitude\n",
    "                            #Label Tristeza/Pena is Sadness\n",
    "                            #Label Enfado/Desprecio/Burla is Anger/contempt/mockery\n",
    "                            #Label Comprensión/Empatía/Identificación is Comprehension/empathy/identification\n",
    "                    },\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": row['Text']  \n",
    "                    },\n",
    "                    {\n",
    "                        \"role\": \"assistant\",\n",
    "                        \"content\": row['Emotions'] \n",
    "                    }\n",
    "                ]\n",
    "        }\n",
    "        \n",
    "        \n",
    "        file.write(json.dumps(data) + \"\\n\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e47e7cd",
   "metadata": {},
   "source": [
    "# Database partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da035a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_json(input_file, output_file_1, output_file_2):\n",
    "    with open(input_file, 'r') as f:\n",
    "        data = [json.loads(line) for line in f]\n",
    "    \n",
    "    total_messages = len(data)\n",
    "\n",
    "    num_messages_1 = int(total_messages * 0.7)\n",
    "    num_messages_2 = total_messages - num_messages_1\n",
    "\n",
    "    shuffled_data = data[:]\n",
    "    random.shuffle(shuffled_data)\n",
    "\n",
    "    data_1 = shuffled_data[:num_messages_1]\n",
    "    data_2 = shuffled_data[num_messages_1:]\n",
    "\n",
    "    with open(output_file_1, 'w') as f1:\n",
    "        for item in data_1:\n",
    "            json.dump(item, f1)\n",
    "            f1.write('\\n')  \n",
    "\n",
    "    with open(output_file_2, 'w') as f2:\n",
    "        for item in data_2:\n",
    "            json.dump(item, f2)\n",
    "            f2.write('\\n')  \n",
    "\n",
    "\n",
    "split_json(\"base_datos.jsonl\", \"training_file.jsonl\", \"test_file.jsonl\")\n",
    "\n",
    "#Label \"base_datos.jsonl\" is data_base.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1d919a",
   "metadata": {},
   "source": [
    "# Code to convert the test file from Excel to JSON format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76d1e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test_file.jsonl\", \"r\") as file:\n",
    "    datos = [json.loads(line) for line in file] #Label \"datos\" is data\n",
    "\n",
    "textos = [] #Label \"textos\" is texts\n",
    "emociones = [] #Label \"emociones\" is emotions\n",
    "\n",
    "for dato in datos:\n",
    "    textos.append(dato[\"messages\"][1][\"content\"])\n",
    "    emociones.append(dato[\"messages\"][2][\"content\"])\n",
    "\n",
    "\n",
    "df = pd.DataFrame({\"Texto\": textos, \"Emociones\": emociones})\n",
    "\n",
    "\n",
    "df.to_excel(\"datos_test.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db904e7a",
   "metadata": {},
   "source": [
    "# Training data verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a65c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "data_path = \"training_file.jsonl\"\n",
    "\n",
    "# Load the dataset\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "  dataset = [json.loads(line) for line in f]\n",
    "\n",
    "# Initial dataset stats\n",
    "print(\"Num examples:\", len(dataset))\n",
    "\n",
    "# Format error checks\n",
    "format_errors = defaultdict(int)\n",
    "\n",
    "for ex in dataset:\n",
    "  if not isinstance(ex, dict):\n",
    "    format_errors[\"data_type\"] += 1\n",
    "    continue\n",
    "\n",
    "  messages = ex.get(\"messages\", None)\n",
    "  if not messages:\n",
    "    format_errors[\"missing_messages_list\"] += 1\n",
    "    continue\n",
    "\n",
    "  for message in messages:\n",
    "    if \"role\" not in message or \"content\" not in message:\n",
    "      format_errors[\"message_missing_key\"] += 1\n",
    "\n",
    "    if any(k not in (\"role\", \"content\", \"name\", \"function_call\") for k in message):\n",
    "      format_errors[\"message_unrecognized_key\"] += 1\n",
    "\n",
    "    if message.get(\"role\", None) not in (\"system\", \"user\", \"assistant\", \"function\"):\n",
    "      format_errors[\"unrecognized_role\"] += 1\n",
    "\n",
    "    content = message.get(\"content\", None)\n",
    "    function_call = message.get(\"function_call\", None)\n",
    "\n",
    "    if (not content and not function_call) or not isinstance(content, str):\n",
    "      format_errors[\"missing_content\"] += 1\n",
    "\n",
    "  if not any(message.get(\"role\", None) == \"assistant\" for message in messages):\n",
    "    format_errors[\"example_missing_assistant_message\"] += 1\n",
    "\n",
    "if format_errors:\n",
    "  print(\"Found errors:\")\n",
    "  for k, v in format_errors.items():\n",
    "    print(f\"{k}: {v}\")\n",
    "else:\n",
    "  print(\"No errors found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bdab54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "# not exact!\n",
    "# simplified from https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb\n",
    "def num_tokens_from_messages(messages, tokens_per_message=3, tokens_per_name=1):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        num_tokens += tokens_per_message\n",
    "        for key, value in message.items():\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "            if key == \"name\":\n",
    "                num_tokens += tokens_per_name\n",
    "    num_tokens += 3\n",
    "    return num_tokens\n",
    "\n",
    "def num_assistant_tokens_from_messages(messages):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        if message[\"role\"] == \"assistant\":\n",
    "            num_tokens += len(encoding.encode(message[\"content\"]))\n",
    "    return num_tokens\n",
    "\n",
    "def print_distribution(values, name):\n",
    "    print(f\"\\n#### Distribution of {name}:\")\n",
    "    print(f\"min / max: {min(values)}, {max(values)}\")\n",
    "    print(f\"mean / median: {np.mean(values)}, {np.median(values)}\")\n",
    "    print(f\"p5 / p95: {np.quantile(values, 0.1)}, {np.quantile(values, 0.9)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7f1a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Warnings and tokens counts\n",
    "n_missing_system = 0\n",
    "n_missing_user = 0\n",
    "n_messages = []\n",
    "convo_lens = []\n",
    "assistant_message_lens = []\n",
    "\n",
    "for ex in dataset:\n",
    "    messages = ex[\"messages\"]\n",
    "    if not any(message[\"role\"] == \"system\" for message in messages):\n",
    "        n_missing_system += 1\n",
    "    if not any(message[\"role\"] == \"user\" for message in messages):\n",
    "        n_missing_user += 1\n",
    "    n_messages.append(len(messages))\n",
    "    convo_lens.append(num_tokens_from_messages(messages))\n",
    "    assistant_message_lens.append(num_assistant_tokens_from_messages(messages))\n",
    "    \n",
    "print(\"Num examples missing system message:\", n_missing_system)\n",
    "print(\"Num examples missing user message:\", n_missing_user)\n",
    "print_distribution(n_messages, \"num_messages_per_example\")\n",
    "print_distribution(convo_lens, \"num_total_tokens_per_example\")\n",
    "print_distribution(assistant_message_lens, \"num_assistant_tokens_per_example\")\n",
    "n_too_long = sum(l > 4096 for l in convo_lens)\n",
    "print(f\"\\n{n_too_long} examples may be over the 4096 token limit, they will be truncated during fine-tuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857b32b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pricing and default n_epochs estimate\n",
    "MAX_TOKENS_PER_EXAMPLE = 4096\n",
    "MIN_TARGET_EXAMPLES = 100\n",
    "MAX_TARGET_EXAMPLES = 25000\n",
    "TARGET_EPOCHS = 3\n",
    "MIN_EPOCHS = 1\n",
    "MAX_EPOCHS = 25\n",
    "\n",
    "n_epochs = TARGET_EPOCHS\n",
    "n_train_examples = len(dataset)\n",
    "if n_train_examples * TARGET_EPOCHS < MIN_TARGET_EXAMPLES:\n",
    "     n_epochs = min(MAX_EPOCHS, MIN_TARGET_EXAMPLES // n_train_examples)\n",
    "elif n_train_examples * TARGET_EPOCHS > MAX_TARGET_EXAMPLES:\n",
    "    n_epochs = max(MIN_EPOCHS, MAX_TARGET_EXAMPLES // n_train_examples)\n",
    "\n",
    "n_billing_tokens_in_dataset = sum(min(MAX_TOKENS_PER_EXAMPLE, length) for length in convo_lens)\n",
    "print(f\"Dataset has ~{n_billing_tokens_in_dataset} tokens that will be charged for during training\")\n",
    "print(f\"By default, you'll train for {n_epochs} epochs on this dataset\")\n",
    "print(f\"By default, you'll be charged for ~{n_epochs * n_billing_tokens_in_dataset} tokens\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82a02a0",
   "metadata": {},
   "source": [
    "# Fine-tuning process execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ef09c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#API key of the OpenAI account\n",
    "openai.api_key='XXXXXXXXXXXX'\n",
    "\n",
    "#Start wandb\n",
    "wandb.init(project=\"Analysis of Emotions\") \n",
    "\n",
    "#Definition of the client\n",
    "client = OpenAI(api_key='XXXXXXXXXXXXX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b68cf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_file = client.files.create(\n",
    "  file=open(\"training_file.jsonl\", \"rb\"),\n",
    "  purpose='fine-tune'\n",
    ")\n",
    "\n",
    "training_file_id = training_file.id\n",
    "print(\"File has been uploaded to OpenAI with id \", training_file_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbda1fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_job = client.fine_tuning.jobs.create(\n",
    "    training_file=training_file_id,\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    hyperparameters={\n",
    "        \"n_epochs\": 3\n",
    "    },\n",
    "    integrations=[\n",
    "        {\n",
    "            \"type\": \"wandb\",\n",
    "            \"wandb\": {\n",
    "                \"project\": wandb.run.project,\n",
    "                \"name\": \"mental-health-model\"\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "model_id = ft_job.id\n",
    "print(\"Fine Tune Job has been created with id \", ft_job.id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e8c96e",
   "metadata": {},
   "source": [
    "# Fine-tuned model verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b367b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "RATE_LIMIT_TPM=60000\n",
    "@sleep_and_retry\n",
    "@limits(calls=RATE_LIMIT_TPM, period=60)  # 60 seconds in a minute\n",
    "\n",
    "# Label \"¿Cuál es la emoción del siguiente texto? is \"What is the emotion of the following text?\"\" \n",
    "#Respond with 'Love/Admiration,' 'Sadness,' 'Neutral,' 'Gratitude,' 'Anger/Contempt/Mockery,' or 'Comprehension/Empathy/Identification'\n",
    "                        \n",
    "#Label Amor/Admiración is Love/admiration\n",
    "#Label Gratitud is Gratitude \n",
    "#Label Tristeza/Pena is Sadness\n",
    "#Label Enfado/Desprecio/Burla is Anger/contempt/mockery\n",
    "#Label Comprensión/Empatía/Identificación is Comprehension/empathy/identification\n",
    "def realizar_solicitud(texto):\n",
    "   \n",
    "    completion = client.chat.completions.create(\n",
    "        model=model_id,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"¿Cuál es la emoción del siguiente texto? Responde con 'Amor/Admiración', 'Tristeza/Pena', 'Indeterminado', 'Gratitud', 'Enfado/Desprecio/Burla' o 'Comprensión/Empatía/Identificación'.\"},\n",
    "            {\"role\": \"user\", \"content\": texto},\n",
    "        ]\n",
    "    )\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d1d8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'datos_test.xlsx'\n",
    "df= pd.read_excel(filename)\n",
    "\n",
    "model_id=\"ft:gpt-3.5-turbo-0125:personal::9O5kGFeK\"\n",
    "\n",
    "sentimiento_clases=[\"Amor/Admiración\", \"Tristeza/Pena\", \"Indeterminado\", \"Gratitud\", \"Enfado/Desprecio/Burla\", \"Comprensión/Empatía/Identificación\"]\n",
    "#Label Amor/Admiración is Love/admiration\n",
    "#Label Gratitud is Gratitude \n",
    "#Label Tristeza/Pena is Sadness\n",
    "#Label Enfado/Desprecio/Burla is Anger/contempt/mockery\n",
    "#Label Comprensión/Empatía/Identificación is Comprehension/empathy/identification\n",
    "\n",
    "\n",
    "predicciones=[] #Label \"predicciones\" is predictions\n",
    "etiquetas_verdaderas=[] #Label \"etiquetas_verdaderas\" is true_labels\n",
    "\n",
    "\n",
    "df_resultados = pd.DataFrame(columns=[\"Comentario\", \"Predicción\", \"Etiqueta Verdadera\"])\n",
    "\n",
    "#Label \"Comentario\" is Comment\n",
    "#Label \"Predicción\" is Prediction\n",
    "#Label \"Etiqueta Verdadera\" is True Label\n",
    "\n",
    "\n",
    "for index, row in df.iterrows(): \n",
    "    texto = row['Texto'] #Label \"texto\" is text\n",
    "    \n",
    "    try: \n",
    "        \n",
    "        response= realizar_solicitud(texto)\n",
    "        predicciones_completas=response   \n",
    "        #Label \"predicciones_completas\" is complete_predictions\n",
    "        \n",
    "        etiqueta=sentimiento_clases.index(response)\n",
    "        #Label \"sentimiento_clases\" is class_sentiment\n",
    "        \n",
    "        predicciones.append(sentimiento_clases[etiqueta])\n",
    "        \n",
    "        true_label = row['Emociones']\n",
    "        \n",
    "        etiquetas_verdaderas.append(true_label)\n",
    "        \n",
    "        df_resultados = pd.concat([df_resultados, pd.DataFrame({\"Comentario\": [texto], \"Predicción\": [response], \"Etiqueta Verdadera\": [true_label]})], ignore_index=True)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "        continue\n",
    "        \n",
    "\n",
    "wandb.log({\"predicciones_vs_etiquetas_verdaderas\": wandb.Table(dataframe=df_resultados)})\n",
    "        \n",
    "report = classification_report(etiquetas_verdaderas, predicciones, target_names=sentimiento_clases)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7319bb09",
   "metadata": {},
   "source": [
    "### Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faaa777c",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(etiquetas_verdaderas, predicciones)\n",
    "print(\"Reporte de clasificación:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a579b295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to upload the classification report to wandb\n",
    "lines = report.split('\\n')\n",
    "\n",
    "lines = [line for line in lines if line.strip()]\n",
    "\n",
    "\n",
    "table_data = []\n",
    "\n",
    "\n",
    "for line in lines:\n",
    "    parts = line.split()\n",
    "    parts = [part for part in parts if part]\n",
    "\n",
    "   \n",
    "    if len(parts) == 5 and parts[0] != 'accuracy':\n",
    "        class_name = parts[0]\n",
    "        precision = parts[1]\n",
    "        recall = parts[2]\n",
    "        f1_score = parts[3]\n",
    "        support = parts[4]\n",
    "        \n",
    "       \n",
    "        table_data.append([class_name, precision, recall, f1_score, support])\n",
    "\n",
    "\n",
    "columns = [\"Clase\", \"Precision\", \"Recall\", \"F1-score\", \"Soporte\"]\n",
    "\n",
    "#Label \"Clase\" is Class\n",
    "#Label \"Soporte\" is Support\n",
    "\n",
    "wandb.log({\"classification_report\": wandb.Table(data=table_data, columns=columns)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0ce3c0",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b00d4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix= confusion_matrix(etiquetas_verdaderas, predicciones, labels=sentimiento_clases)\n",
    "# Imprimir la matriz de confusión\n",
    "print(\"Confusion Matrix:\")\n",
    "print(matrix)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "vis.plot(ax=ax, cmap=plt.cm.Blues) \n",
    "\n",
    "ax.set_xticklabels(sentimiento_clases, rotation=45, ha=\"right\")\n",
    "\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.tight_layout()\n",
    "\n",
    "img_path = \"confusion_matrix.png\"\n",
    "plt.savefig(img_path)\n",
    "\n",
    "wandb.log({\"confusion_matrix\": wandb.Image(img_path)})\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a22b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4b2499",
   "metadata": {},
   "source": [
    "# Example of using the OpenAI model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34435eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "completation = client.chat.completions.create(\n",
    "    model=\"ft:gpt-3.5-turbo-0125:personal::9O5kGFeK\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\":\"¿Cuál es el sentimiento del siguiente texto? Responde con 'Amor/Admiración', 'Tristeza/Pena', 'Indeterminado', 'Gratitud', 'Enfado/Desprecio/Burla' o 'Comprensión/Empatía/Identificación'.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Gracias por compartirlo.... Somos humanos... A veces es tan simple como reconocernos humanos.... Un beso\"},\n",
    "    ]\n",
    ")\n",
    "    \n",
    "print(completation.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f5a7e5",
   "metadata": {},
   "source": [
    "# Function predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd98de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function predict emotions\n",
    "def predict_emotions(text):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"ft:gpt-3.5-turbo-0125:personal::9O5kGFeK\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\":\"¿Cuál es el sentimiento del siguiente texto? Responde con 'Amor/Admiración', 'Tristeza/Pena', 'Indeterminado', 'Gratitud', 'Enfado/Desprecio/Burla' o 'Comprensión/Empatía/Identificación'.\"},\n",
    "            {\"role\": \"user\", \"content\": text},\n",
    "        ]\n",
    "    )\n",
    "    return completion.choices[0].message.content.strip()\n",
    "\n",
    "#Example\n",
    "input_text= \"Gracias por compartirlo\"\n",
    "emocion_predicha= predict_emotions(input_text)\n",
    "print(emocion_predicha)\n",
    "\n",
    "\n",
    "#Function predict emotions from an excel \n",
    "def predict_emotions_excel(input_file, output_file, text_column):\n",
    "    #Upload the excel input file\n",
    "    df=pd.read_excel(input_file)\n",
    "    \n",
    "    df['Emotion']=df[text_column].apply(predict_emotions)\n",
    "    df.to_excel(output_file, index=False)\n",
    "    \n",
    "    print(output_file)\n",
    "    \n",
    "#Example\n",
    "input_file=\"\" #Write an input file\n",
    "output_file=\"\" #Write an output file where do you what all the predictions\n",
    "text_column=\"\" #Write the name of the column where all the text  you want to predict are. \n",
    "\n",
    "predict_emotions_excel(input_file, output_file, text_column)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
